{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (4.21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from transformers) (1.23.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from transformers) (2022.7.25)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from requests->transformers) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (22.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What do these things do?\n",
    "\n",
    "Tokenizer: takes our input text and encode it from a word to a number\n",
    "\n",
    "LMHeadModel: will generate outputs tokens (numbers) which represents words. Then we will use the tokenizer again to decode those numbers back to words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justjp/opt/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (1.12.0)\n",
      "Requirement already satisfied: torchvision in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (0.13.0)\n",
      "Requirement already satisfied: torchaudio in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (0.12.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: numpy in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from torchvision) (1.23.1)\n",
      "Requirement already satisfied: requests in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/justjp/opt/miniconda3/lib/python3.10/site-packages (from requests->torchvision) (2022.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model\n",
    "\n",
    "tokenizer = allows us to leverage the gpt2-large model which a pre-trained model on English language\n",
    "\n",
    "model = the pad_token_id lets us see what token is going to be used to pad our text. EOS stands for (end of sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|██████████| 3.02G/3.02G [01:16<00:00, 42.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-large', pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize Sentences\n",
    "\n",
    "Tokenization = the process of converting a string to a sequence of numbers.\n",
    "\n",
    "We have taken our text and use the tokenizer to encode into a number of differnt identifies. The indentifies are going to be what we use to pass to our model. We want to return our tensors as pytorch tensors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Creativity Is a Process, Not an Event\"\n",
    "input_ids = tokenizer.encode(sentence, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So we have converted our sentence into input ids \n",
    "\n",
    "We convert them into numbers because this is the way the GPT2 model likes receiving inputs. The GPT2 model is going to generate our blog post into numbers which means we will have to use the tokenizer again to decode it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Since the index starts at [0][0] it returns 'Why'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Creativity Is a Process, Not an Event'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16719,  3458,  1148,   257, 10854,    11,  1892,   281,  8558]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate & Decode Text\n",
    "\n",
    "output = our input ids which we encoded to turn them into numbers. \n",
    "    max_length is the length of the text we want to generate. \n",
    "    num_beams (beam search) finds the best next word to be used in the sequence. We set the number of search trees were going to have to 5\n",
    "    no_repeat_ngram = stops our model from repeating certaiin sequences over and over again. We set it to 2 so it can only repeat once.\n",
    "    early_stopping = if we reach a point where we aren't getting great outputs, it will stop generating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(input_ids, max_length = 550, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16719,  3458,  1148,   257, 10854,    11,  1892,   281,  8558,     1,\n",
       "           198,   198,     1,   464,  7325,  1429,   318,   257,  1429,    11,\n",
       "           407,   281,  1785,     1,   318,   530,   286,   262,   749,  2219,\n",
       "         20144,   973,   284,  6901,   262,  1429,   286, 16389,    13,   632,\n",
       "           318,  1690,   973,   355,   257,  6171,  5177,   329,   366, 20123,\n",
       "          3458,   553,   475,   340,   318,   407,   262,   976,  1517,    13,\n",
       "          7921,  3458,   318,   262,  2694,   284,  2251,  1223,   649,    11,\n",
       "          1223,   326,   318,  1180,   422,   644,   468,   587,  1760,   878,\n",
       "            13,   383,  1429,   416,   543, 16389,   318,  2727,   318,  1444,\n",
       "           366,  1169,  7325,   719,   553,   290,   340,   460,   307,  1807,\n",
       "           286,   355,   281,  7044,  1429,   287,   543,   649,  4213,   389,\n",
       "          7558,   852,  2727,   290, 20449,  1566,   484,   389,  3492,   284,\n",
       "           307,  1234,   284,   779,   287,   262,  6282,   286,   257,   649,\n",
       "           670,   286,  1242,    11,   257,  5337,    11,   393,   257,  3704,\n",
       "           286,  2647,    13,   554,   584,  2456,    11,  7325,   670,   318,\n",
       "          1464, 21568,    11,  1464,  5609,    11,   290,  1464,   287,  2989,\n",
       "           286,   649,   290,  1365,  2842,   284,  4911,   262,  4213,   326,\n",
       "           423,  1541,   587,  6241,    13,   770,   318,   644,  1838, 16389,\n",
       "           884,   281,  1593,   636,   286,  1692,  1204,    13,   628,   198,\n",
       "           818,  1502,   284,  1833,   703, 16389,  2499,    11,   356,  1276,\n",
       "           717,  1833,   262,  3450,   286,  4213,    13, 35365,   389,   262,\n",
       "          4096,  2615,  7021,   286,   477,  1692,  1807,   290,  2223,    13,\n",
       "          3887,  1692,   852,   468,   281,  2126,   286,   644,   339,   393,\n",
       "           673,   318,  1016,   284,   466,  1306,    11,   475,   691,   257,\n",
       "          1402,  5873,   286,   777,  4213,   481,  1683,  1716,  4036,  1143,\n",
       "           287,   257, 10017,   835,    13,  1114,  1672,    11,   611,   345,\n",
       "           423,   257,   922,  2126,   329,   257,  3807,    11,   345,   481,\n",
       "          2192,  1239,  1682,   787,   262,  3807,    13,  2102,    11,   262,\n",
       "          2126,   481,   307,   612,   287,   534,  2000,    11,  4953,   329,\n",
       "           345,   284,  1011,  2223,   319,   340,    13,  1002,   345,  1011,\n",
       "           262,   640,   284,   892,   546,   644,   345,   765,   284,  9989,\n",
       "           351,   534,  2126,    11,   788,   345,   460,  2221,   284,   766,\n",
       "           703,   340,  1244,   307,  1744,   284,   787,   340,   257,  3950,\n",
       "            13,   921,  1244,   772,   307,  1498,   284,  1282,   510,   351,\n",
       "           257,  1365,  2126,   621,   262,   530,   345,  6198,   550,   287,\n",
       "          2000,    13,  1081,   890,   355,   345,   389,  4684,   284,   670,\n",
       "           319,   534,  4213,    11,   484,   481,  4191,  1282,   284, 41675,\n",
       "           290,  1716,   257,  1103,  3807,   393,  5337,   326,   345,   290,\n",
       "           534,  2460,   460,   477,  2883,  1978,    13,  1649,   345,   923,\n",
       "           284,   804,   379,  4213,   287,   428,   835,    11,   340,  4329,\n",
       "          1598,   326,   612,   318,   645,   884,  1517,   355,   366,   272,\n",
       "          2126,   526,  1318,   389,   645,   366,   485,   292,     1,   326,\n",
       "           389,   366,   259,  1151,   276,     1,   393,   366, 25598,     1,\n",
       "           416,   597,   530,  1048,   393,  1448,   286,   661,    13,  5455,\n",
       "            11,   612,   389,  4213,   543,   389,  2727,   416,   477,   286,\n",
       "           514,   355,   356,   467,   546,   674,  4445,  3160,    13,   775,\n",
       "           477,   423,  4213,   546,   703,   356,   815,  2107,   674,  3160,\n",
       "            11,   644,   674,  4661,   815,   307,    11,   703,   284,   651,\n",
       "          1863,   351,   674,  1641,    11,  2460,    11,   763,    12, 22896,\n",
       "            11,  3503,    13,  2312,  4213,  1282,   422,   257,  4996,   286,\n",
       "          4237,    11,   884,   355,   674,   898,  6461,   290,   262,  6461,\n",
       "           286,  1854,    11,   355,   880,   355,   422,  3835,    11,  6918,\n",
       "            11,  5581,  2523,    11,  2647,    11, 19518,    11,  8876,    11,\n",
       "          5737,    11,  3783,    11,  3037,    11,  4819,    11,  1597,    11,\n",
       "          5701,    11,  1242,   290,   584,  5107,   286, 17290,  5408,    13]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding\n",
    "\n",
    "By decoding the output we are getting back our input and the ouput text added to it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Creativity Is a Process, Not an Event\"\\n\\n\"The creative process is a process, not an event\" is one of the most common phrases used to describe the process of creativity. It is often used as a synonym for \"creativity,\" but it is not the same thing. Creativity is the ability to create something new, something that is different from what has been done before. The process by which creativity is created is called \"the creative act,\" and it can be thought of as an ongoing process in which new ideas are constantly being created and refined until they are ready to be put to use in the creation of a new work of art, a novel, or a piece of music. In other words, creative work is always evolving, always changing, and always in search of new and better ways to express the ideas that have already been expressed. This is what makes creativity such an important part of human life.\\n\\n\\nIn order to understand how creativity works, we must first understand the nature of ideas. Ideas are the basic building blocks of all human thought and action. Every human being has an idea of what he or she is going to do next, but only a small percentage of these ideas will ever become actualized in a concrete way. For example, if you have a good idea for a movie, you will probably never actually make the movie. However, the idea will be there in your mind, waiting for you to take action on it. If you take the time to think about what you want to accomplish with your idea, then you can begin to see how it might be possible to make it a reality. You might even be able to come up with a better idea than the one you originally had in mind. As long as you are willing to work on your ideas, they will eventually come to fruition and become a real movie or novel that you and your friends can all enjoy together. When you start to look at ideas in this way, it becomes clear that there is no such thing as \"an idea.\" There are no \"ideas\" that are \"invented\" or \"created\" by any one person or group of people. Instead, there are ideas which are created by all of us as we go about our daily lives. We all have ideas about how we should live our lives, what our goals should be, how to get along with our family, friends, co-workers, etc. These ideas come from a variety of sources, such as our own experiences and the experiences of others, as well as from books, movies, television shows, music, poetry, philosophy, religion, science, technology, politics, business, sports, art and other forms of artistic expression.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing the 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog = tokenizer.decode(output[0], special_tokens=True).replace('\\n', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Creativity Is a Process, Not an Event\"\"The creative process is a process, not an event\" is one of the most common phrases used to describe the process of creativity. It is often used as a synonym for \"creativity,\" but it is not the same thing. Creativity is the ability to create something new, something that is different from what has been done before. The process by which creativity is created is called \"the creative act,\" and it can be thought of as an ongoing process in which new ideas are constantly being created and refined until they are ready to be put to use in the creation of a new work of art, a novel, or a piece of music. In other words, creative work is always evolving, always changing, and always in search of new and better ways to express the ideas that have already been expressed. This is what makes creativity such an important part of human life.In order to understand how creativity works, we must first understand the nature of ideas. Ideas are the basic building blocks of all human thought and action. Every human being has an idea of what he or she is going to do next, but only a small percentage of these ideas will ever become actualized in a concrete way. For example, if you have a good idea for a movie, you will probably never actually make the movie. However, the idea will be there in your mind, waiting for you to take action on it. If you take the time to think about what you want to accomplish with your idea, then you can begin to see how it might be possible to make it a reality. You might even be able to come up with a better idea than the one you originally had in mind. As long as you are willing to work on your ideas, they will eventually come to fruition and become a real movie or novel that you and your friends can all enjoy together. When you start to look at ideas in this way, it becomes clear that there is no such thing as \"an idea.\" There are no \"ideas\" that are \"invented\" or \"created\" by any one person or group of people. Instead, there are ideas which are created by all of us as we go about our daily lives. We all have ideas about how we should live our lives, what our goals should be, how to get along with our family, friends, co-workers, etc. These ideas come from a variety of sources, such as our own experiences and the experiences of others, as well as from books, movies, television shows, music, poetry, philosophy, religion, science, technology, politics, business, sports, art and other forms of artistic expression.'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Results\n",
    "\n",
    "We have used our tokenizer to decode our outputs.\n",
    "We are grabbing the first part of our text\n",
    "We use skip_special_token so we don't output the end of text token and other tokens\n",
    "\n",
    "'w' = specifies that we want to write it out\n",
    "as f = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('creativity_is_a_process.txt', 'w') as f:\n",
    "    f.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4a77a2c06191c0940cf5c00b1e8c84f0c16922c932450ddefb8dd26f4927432"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
